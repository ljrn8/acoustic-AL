{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:02:59.349702: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 14:02:59.349740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 14:02:59.350813: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-25 14:02:59.357687: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 14:03:00.117832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow  import keras\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from util import open_slideshow\n",
    "\n",
    "\n",
    "import librosa \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from config import *\n",
    "import h5py\n",
    "import soundfile as sf\n",
    "from scipy.signal import resample_poly\n",
    "from util import DEFAULT_TOKENS\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16_000\n",
    "EMBEDDS = INTERMEDIATE / 'embeddings_20p.hdf5'\n",
    "SAMPLES = INTERMEDIATE / '22sr_samples.hdf5'\n",
    "OVERLAP_THRESH =  0.20 \n",
    "\n",
    "samples_f = h5py.File(SAMPLES, 'r')\n",
    "embedds_f = h5py.File(EMBEDDS, 'a')\n",
    "\n",
    "all_recs = np.load(ANNOTATIONS / 'manual_annotations' / 'all_annotated_recordings_filtered.npy', allow_pickle=True)\n",
    "annotations = pd.read_csv(ANNOTATIONS / 'manual_annotations' / 'initial_manual_annotations.csv')\n",
    "annotated_recordings = annotations.recording.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starts at  9661834\n",
      "[9625586 9635706 9642160 9654186 9658733 9670173 9676773 9686893 9694226\n",
      " 9706253]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9658733, 9670173)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label_bounds(some_labelled_sample, label_idx, Y_samples):\n",
    "    def find_surrounding_values(arr, x):\n",
    "        if len(arr) < 2:\n",
    "            return None\n",
    "\n",
    "        for i in range(len(arr) - 1):\n",
    "            if arr[i] <= x < arr[i + 1]:\n",
    "                return (arr[i], arr[i + 1])\n",
    "        \n",
    "        return None \n",
    "    \n",
    "    diff = np.diff(Y_samples[label_idx, :])\n",
    "    change_samples = np.where(diff)[0] + 1 # change is before\n",
    "    print(change_samples)\n",
    "    return find_surrounding_values(change_samples, some_labelled_sample)\n",
    "    \n",
    "    \n",
    "# test\n",
    "rec = annotated_recordings[0]\n",
    "s_22, Y_samples = np.array(samples_f[rec]['X']), np.array(samples_f[rec]['Y'])\n",
    "rows, cols = np.where(Y_samples.T)\n",
    "print('starts at ', rows[25246+1])\n",
    "get_label_bounds(rows[25246+1], cols[25246+1], Y_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1250),\n",
       " 20,\n",
       " array([[False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False],\n",
       "        [ True,  True, False,  True,  True, False,  True, False, False,\n",
       "          True,  True, False,  True,  True, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERCENTAGES = {\n",
    "    'fast_trill_6khz': None,\n",
    "    'nr_syllable_3khz': 0.90, \n",
    "    'triangle_3khz': 0.80,\n",
    "    'upsweep_500hz': 0.80,\n",
    "}\n",
    "\n",
    "def fill_Y_with_label(n_frames, label_type, labels):\n",
    "    frame_length = 0.96\n",
    "    step_size = 0.48\n",
    "    Y_row = np.zeros(n_frames)\n",
    "    label_idx = DEFAULT_TOKENS[label_type]\n",
    "    \n",
    "    # frames across the recording \n",
    "    for i in range(n_frames):\n",
    "        frame_start = i * step_size\n",
    "        frame_end = frame_start + frame_length\n",
    "        \n",
    "        # how much of the label is required to be within the frame\n",
    "        percent_required = PERCENTAGES[label_type]\n",
    "        \n",
    "        # all labels contained in this frame or contain the frame itself\n",
    "        contained_labels = [\n",
    "            (s, e) for s, e in labels \n",
    "            if (frame_start < s < frame_end) and (frame_start < e < frame_end)\n",
    "        ]\n",
    "        encapsulating_labels = [\n",
    "            (s, e) for s, e in labels \n",
    "            if (s < frame_start) and (frame_end < e)\n",
    "        ]\n",
    "        if len(contained_labels) > 0 or len(encapsulating_labels) > 0:\n",
    "            Y_row[i] = 1 \n",
    "        \n",
    "        # labels that start in this frame only\n",
    "        starting_labels = [\n",
    "            (s, e) for s, e in labels\n",
    "            if frame_start < s < frame_end\n",
    "        ]\n",
    "        for (s, e) in starting_labels:\n",
    "            if label_type == 'fast_trill_6khz':\n",
    "                if (frame_end - s) > 0.6: # atleast 0.6 seconds required\n",
    "                    Y_row[i] = 1  \n",
    "            else:\n",
    "                if (frame_end - s) / (e - s) > percent_required:\n",
    "                    Y_row[i] = 1  \n",
    "            \n",
    "        # labels that end in this frame only\n",
    "        ending_labels = [\n",
    "            (s, e) for s, e in labels \n",
    "            if frame_start < e < frame_end\n",
    "        ]\n",
    "        for (s, e) in ending_labels:\n",
    "            if label_type == 'fast_trill_6khz':\n",
    "                if (e - frame_start) > 0.6:\n",
    "                    Y_row[i] = 1\n",
    "            else:\n",
    "                if (e - frame_start) / (e - s) > percent_required:\n",
    "                    Y_row[i] = 1  \n",
    "               \n",
    "                 \n",
    "    return Y_row\n",
    "\n",
    "\n",
    "def get_label_pairs(label_df):\n",
    "    label_start_times, label_end_times = (\n",
    "        np.array(label_df[\"min_t\"].astype(float)), \n",
    "        np.array(label_df[\"max_t\"].astype(float))\n",
    "    )\n",
    "    return list(zip(label_start_times, label_end_times))\n",
    "\n",
    "\n",
    "def compute_frame_labels(rec, annotations_df):\n",
    "    n_samples = len(samples_f[rec]['X'])\n",
    "    n_seconds = n_samples / 22_000\n",
    "    n_frames = int(n_seconds / 0.48)\n",
    "    annotated_recordings = annotations_df.recording.unique()\n",
    "    Y_frames = np.zeros(shape=(4, n_frames), dtype=bool) \n",
    "    \n",
    "    # all 0s if no annotations present\n",
    "    if rec not in annotated_recordings:\n",
    "        return Y_frames\n",
    "    \n",
    "    rec_df = annotations_df[annotations_df.recording == rec]\n",
    "    for label, label_index in DEFAULT_TOKENS.items():\n",
    "        \n",
    "        # start and end times of annotations for this label\n",
    "        labels = get_label_pairs(rec_df[rec_df.label == label])\n",
    "        Y_frames[label_index] = fill_Y_with_label(n_frames, label, labels)\n",
    "             \n",
    "    return Y_frames\n",
    "\n",
    "\n",
    "# test this ^^^\n",
    "rec = annotated_recordings[1]\n",
    "Y_frames = compute_frame_labels(rec, annotations)\n",
    "Y_frames.shape, Y_frames.sum(), Y_frames[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1250),\n",
       " 33,\n",
       " array([[False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(embedds_f[rec]['Y'])\n",
    "y.shape, y.sum(), y[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'n# annotated recs: ', len(annotated_recordings))\n",
    "print(f'n# total \\'annotated\\' recs: ', len(all_recs))\n",
    "print(f'n# of annotations: ', len(annotations))\n",
    "\n",
    "from util import DEFAULT_TOKENS\n",
    "order = list(DEFAULT_TOKENS.keys())\n",
    "IMAGE_FOLDER = Path('../untracked/labeltest')\n",
    "IMAGE_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "for rec in tqdm(annotated_recordings[:30]):\n",
    "    \n",
    "    samples = samples_f[rec]['X']\n",
    "    embedds = embedds_f[rec]['X']\n",
    "\n",
    "    # get labelled frames from above\n",
    "    label_frames = compute_frame_labels(rec, annotations)\n",
    "    cols, rows = np.where(label_frames)\n",
    "    \n",
    "    for i, (r, c) in enumerate(zip(rows, cols)):\n",
    "        start_time = r * 0.48\n",
    "        beginning_sample = librosa.time_to_samples(start_time, sr=22_000)\n",
    "        end_sample = beginning_sample + librosa.time_to_samples(1, sr=22_000)\n",
    "        widen = 1 * 22_000\n",
    "        segment = samples[beginning_sample - widen:end_sample + widen]\n",
    "        \n",
    "        # plot spec\n",
    "        plt.figure(figsize=(2, 3))\n",
    "        S = librosa.stft(segment)\n",
    "        S = librosa.power_to_db(S)\n",
    "        librosa.display.specshow(S)\n",
    "\n",
    "        # add lines around frame\n",
    "        widen_frame = librosa.samples_to_frames(widen)\n",
    "        plt.vlines([widen_frame, widen_frame*2], ymin=0, ymax=500)\n",
    "        \n",
    "        # save fig\n",
    "        plt.title(order[c])\n",
    "        path = IMAGE_FOLDER / order[c]\n",
    "        path.mkdir(exist_ok=True)\n",
    "        plt.savefig(path / f'{rec}_r={r}.png')\n",
    "        ax = plt.clf()\n",
    "\n",
    "    \n",
    "    # embedds_f[rec].create_dataset(\"X_strict\", data=label_frames, dtype=bool)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n# annotated recs:  101\n",
      "n# total 'annotated' recs:  354\n",
      "n# of annotations:  1981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 13/354 [00:00<00:02, 118.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/354 [00:01<00:00, 204.81it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f'n# annotated recs: ', len(annotated_recordings))\n",
    "print(f'n# total \\'annotated\\' recs: ', len(all_recs))\n",
    "print(f'n# of annotations: ', len(annotations))\n",
    "\n",
    "from util import DEFAULT_TOKENS\n",
    "order = list(DEFAULT_TOKENS.keys())\n",
    "\n",
    "for rec in tqdm(list(embedds_f)):\n",
    "    label_frames = compute_frame_labels(rec, annotations)\n",
    "    embedds_f[rec].create_dataset(\"Y_strict\", data=label_frames, dtype=bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedds_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
