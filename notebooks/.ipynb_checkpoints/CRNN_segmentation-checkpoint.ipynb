{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from config import *\n",
    "from preprocessing import SpectrogramSequence\n",
    "from util import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n# frames in chunk:  467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing data: 100%|██████████| 301/301 [00:04<00:00, 73.87it/s]\n"
     ]
    }
   ],
   "source": [
    "sr = 24_000\n",
    "batch_size = 32\n",
    "\n",
    "annotations_df: pd.DataFrame = pd.read_csv(ANNOTATIONS / 'initial_dataset_7depl_metadata.csv')\n",
    "ds: Dataset = Dataset(DATA_ROOT)\n",
    "\n",
    "spectrogram_sequence = SpectrogramSequence(\n",
    "    annotations_df, ds, sr=sr, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 512, 467, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 256, 233, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 256, 233, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 128, 116, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 128, 116, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 64, 58, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 64, 58, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 32, 29, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 237568)            0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 928, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 783,108\n",
      "Trainable params: 783,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_rnn_model(input_shape=(512, 467, 1), num_classes=4):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # CNN layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten the output from CNN\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Reshape the output for RNN input\n",
    "    # !! NOTE only last feature dimension as the time steps\n",
    "    model.add(layers.Reshape((-1, 256)))  # Reshape to (batch_size, time_steps, features)\n",
    "\n",
    "    # RNN layers\n",
    "    model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=False)))\n",
    "    model.add(layers.Dense(num_classes, activation='sigmoid'))  # Use 'sigmoid' for multi-label classification\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_rnn_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading new recording: 1_20230316_063000.wav \t\t\t| Time Taken: 7.580250 seconds\n",
      "resampling 1_20230316_063000.wav \t\t\t| Time Taken: 2.418799 seconds\n",
      "stft 1_20230316_063000.wav \t\t\t| Time Taken: 1.301422 seconds\n",
      "converting to db 1_20230316_063000.wav \t\t\t| Time Taken: 0.897259 seconds\n",
      "Total: 12.21 seconds\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 668, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 484, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/optimizer_v2/utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspectrogram_sequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1130\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 668, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 484, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"/home/ethan/.local/lib/python3.8/site-packages/keras/optimizer_v2/utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    spectrogram_sequence,\n",
    "    epochs=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
