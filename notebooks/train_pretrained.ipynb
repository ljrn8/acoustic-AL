{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow  import keras\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "import librosa \n",
    "from util import WavDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(80000,), dtype=float32, numpy=\n",
      "array([-0.00452962, -0.0067026 , -0.00624345, ..., -0.00081211,\n",
      "       -0.00229448, -0.00023884], dtype=float32)>, <tf.Tensor: shape=(9, 4), dtype=bool, numpy=\n",
      "array([[False, False, False, False],\n",
      "       [False, False, False, False],\n",
      "       [False, False, False, False],\n",
      "       [False, False, False, False],\n",
      "       [False, False, False, False],\n",
      "       [False, False, False, False],\n",
      "       [False, False, False, False],\n",
      "       [False, False, False, False],\n",
      "       [False, False, False, False]])>)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from config import *\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def chunk_generator():\n",
    "    chunk_len = 5\n",
    "    overlap = 1\n",
    "    sr = 16_000\n",
    "    hdf5_file = INTERMEDIATE / 'train.hdf5'\n",
    "\n",
    "    chunk_len *= sr\n",
    "    overlap *= sr\n",
    "    with h5py.File(hdf5_file, 'r') as hdf5_dataset:\n",
    "        \n",
    "        # get chunk info and shuffle\n",
    "        chunks = []\n",
    "        for rec in list(hdf5_dataset):\n",
    "            Y = hdf5_dataset[rec]['Y']     \n",
    "            n_samples = Y.shape[1]\n",
    "            chunks += [\n",
    "                (rec, start, start + chunk_len) \n",
    "                for start in range(0, n_samples, chunk_len - overlap)\n",
    "            ]\n",
    "            \n",
    "        np.random.shuffle(chunks)\n",
    "    \n",
    "        # generate chunks\n",
    "        for random_chunk in chunks:\n",
    "            rec, s, e = random_chunk\n",
    "            Y = hdf5_dataset[rec]['Y']  \n",
    "            samples = hdf5_dataset[rec]['X']\n",
    "            s_slice = np.array(samples[s:e])\n",
    "            y_slice = np.array(Y[:, s:e])\n",
    "            \n",
    "            def contract(segment):\n",
    "                return np.array([\n",
    "                    ss.mean() > 0.4 for ss in segment\n",
    "                ])\n",
    "\n",
    "            # https://www.kaggle.com/models/google/yamnet\n",
    "            frame = int(1 * sr)\n",
    "            hop = int(0.5 * sr)\n",
    "            \n",
    "            y_frames = np.array([\n",
    "                contract(y_slice[:, i:i+frame]) for i in range(0, y_slice.shape[1] - (frame - hop) , hop)\n",
    "            ]) # 9 frames \n",
    "            \n",
    "            yield s_slice.T, y_frames # !! TODO veryfy that y is correct\n",
    "            \n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_generator(\n",
    "    chunk_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(9, 4), dtype=tf.bool)))\n",
    "\n",
    "for s in raw_dataset.take(1):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 1024])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, emb, _ = YAMnet(np.zeros(16_000 * 3))\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:51:24 INFO Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "yamnet_url = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_layer = hub.KerasLayer(yamnet_url, input_shape=(None,), dtype=tf.float32, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sample_chunk, Y_chunk):\n",
    "    _, emb, _ = yamnet_layer(sample_chunk)\n",
    "    return emb, Y_chunk \n",
    "\n",
    "full_dataset = raw_dataset.map(lambda x, y: get_embeddings(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 9, 1024)]         0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 9, 256)            262400    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9, 128)            32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 9, 64)             8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 9, 4)              260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 303,812\n",
      "Trainable params: 303,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# inp = keras.Input(shape=(16_000 * 5))\n",
    "# _, embeddings, _ = YAMnet(inp)\n",
    "# output = keras.layers.Dense(4, activation='sigmoid')(embeddings)\n",
    "# model = keras.Sequential(inputs=inp, outputs=output)\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     yamnet_base,\n",
    "#     # tf.keras.layers.GlobalAveragePooling1D(),  # Reduce the dimensionality\n",
    "#     tf.keras.layers.Dense(4, activation='softmax')  # Output layer for classification\n",
    "# ])\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(9, 1024), dtype=tf.float32)\n",
    "x = layers.Dense(256, activation='relu')(inputs)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(4, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',  \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [32,9] vs. [32,10]\n\t [[node Equal\n (defined at /usr/local/lib/python3.8/dist-packages/keras/metrics.py:3566)\n]] [Op:__inference_train_function_17788]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Equal:\nIn[0] ArgMax (defined at /usr/local/lib/python3.8/dist-packages/keras/metrics.py:3567)\t\nIn[1] ArgMax_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 739, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n>>>     await super().execute_request(stream, ident, parent)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n>>>     result = runner(coro)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_14397/1092358387.py\", line 1, in <module>\n>>>     history = model.fit(full_dataset.batch(32), epochs=1)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 817, in train_step\n>>>     self.compiled_metrics.update_state(y, y_pred, sample_weight)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 460, in update_state\n>>>     metric_obj.update_state(y_t, y_p, sample_weight=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/metrics_utils.py\", line 73, in decorated\n>>>     update_op = update_state_fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/metrics.py\", line 177, in update_state_fn\n>>>     return ag_update_state(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/metrics.py\", line 725, in update_state\n>>>     matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/metrics.py\", line 3566, in categorical_accuracy\n>>>     tf.equal(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [32,9] vs. [32,10]\n\t [[node Equal\n (defined at /usr/local/lib/python3.8/dist-packages/keras/metrics.py:3566)\n]] [Op:__inference_train_function_17788]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Equal:\nIn[0] ArgMax (defined at /usr/local/lib/python3.8/dist-packages/keras/metrics.py:3567)\t\nIn[1] ArgMax_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 739, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n>>>     await super().execute_request(stream, ident, parent)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n>>>     result = runner(coro)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"/home/ethan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_14397/1092358387.py\", line 1, in <module>\n>>>     history = model.fit(full_dataset.batch(32), epochs=1)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 817, in train_step\n>>>     self.compiled_metrics.update_state(y, y_pred, sample_weight)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 460, in update_state\n>>>     metric_obj.update_state(y_t, y_p, sample_weight=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/metrics_utils.py\", line 73, in decorated\n>>>     update_op = update_state_fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/metrics.py\", line 177, in update_state_fn\n>>>     return ag_update_state(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/metrics.py\", line 725, in update_state\n>>>     matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/metrics.py\", line 3566, in categorical_accuracy\n>>>     tf.equal(\n>>> "
     ]
    }
   ],
   "source": [
    "history = model.fit(full_dataset.batch(32), epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
