{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 07:55:09.187376: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-22 07:55:09.187420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-22 07:55:09.321899: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-22 07:55:09.583264: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-22 07:55:11.258703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "from os import path\n",
    "from config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(hdf5_dataset):\n",
    "    recordings = np.array(hdf5_dataset)\n",
    "    rec =  recordings[0]\n",
    "    embeddings_frames = []\n",
    "    for rec in recordings:\n",
    "        embeddings_frames.extend([\n",
    "            (rec, i) for i in range(hdf5_dataset[rec]['X'].shape[0])\n",
    "        ])\n",
    "        \n",
    "    return embeddings_frames\n",
    "    \n",
    "    \n",
    "hdf5_dataset = h5py.File(INTERMEDIATE / 'embeddings_20p.hdf5', 'r')\n",
    "embeddings_frames = get_frames(hdf5_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelled, unlabelled and test set init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(embeddings_frames) \n",
    "\n",
    "X = np.array([hdf5_dataset[rec]['X'][frame, :] for (rec, frame) in embeddings_frames])\n",
    "Y = np.array([hdf5_dataset[rec]['Y'][:, frame] for (rec, frame) in embeddings_frames])\n",
    "n_frames = len(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282931 unlabelled \n",
      " 70733 labelled \n",
      " 25.000088360766405% initial labelling budget\n",
      "\n",
      "test XY lens: (88416, 88416)\n",
      "unlabelled XY lens: (282931, 282931)\n",
      "labelled XY lens: (70733, 70733)\n"
     ]
    }
   ],
   "source": [
    "n_frames = len(X) \n",
    "test_cut =  int(n_frames * 0.8)\n",
    "label_cut = int(test_cut * 0.8)\n",
    "\n",
    "# test data\n",
    "other_X, other_Y = X[:test_cut],  Y[:test_cut]\n",
    "test_X, test_Y = X[test_cut:],  Y[test_cut:]\n",
    "\n",
    "# labelled and unlabelled data\n",
    "unlabelled_X, unlabelled_Y = other_X[:label_cut], other_Y[:label_cut]\n",
    "labelled_X, labelled_Y = other_X[label_cut:], other_Y[label_cut:]\n",
    "\n",
    "u, t = len(unlabelled_X), len(labelled_Y),  \n",
    "print(f'{u} unlabelled \\n {t} labelled \\n {(t/u)*100}% initial labelling budget')\n",
    "print(f'\\ntest XY lens: {len(test_X), len(test_Y)}')\n",
    "print(f'unlabelled XY lens: {len(unlabelled_X), len(unlabelled_Y)}')\n",
    "print(f'labelled XY lens: {len(labelled_X), len(labelled_Y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, BatchNormalization\n",
    "from functools import partial\n",
    "from keras import metrics\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def create_model() -> keras.Model:\n",
    "    default_dense =  partial(Dense, activation='relu', \n",
    "                             kernel_initializer=keras.initializers.LecunNormal(seed=0)\n",
    "                            ) \n",
    "    \n",
    "    return keras.Sequential([\n",
    "            Input(shape=(1024,)),\n",
    "            default_dense(512), \n",
    "            # default_dense(64), \n",
    "            Dense(4, activation='sigmoid',)\n",
    "    ])\n",
    "\n",
    "def compile(model):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',  \n",
    "        metrics=[\n",
    "            metrics.Recall(thresholds=0.5),\n",
    "            metrics.Precision(thresholds=0.5),\n",
    "            metrics.AUC(curve='pr', name='auc_pr'),\n",
    "            metrics.AUC(curve='roc', name='auc_roc'), # not applicitory\n",
    "            tfr.keras.metrics.get(key=\"map\", name=\"metric/map\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def train(model, X, Y, model_dir, stopping_patience=5, \n",
    "          stopping_moniter='loss', **kwargs):\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # tensorboard\n",
    "    log_dir = model_dir / \"logs\" / \"fit\"\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    # checkpoints\n",
    "    checkpoint_path = model_dir / \"training\"\n",
    "    Path(checkpoint_path).mkdir(exist_ok=True)  \n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path / 'checkpoint.weights.h5', \n",
    "        save_weights_only=True,\n",
    "        verbose=1, \n",
    "    )\n",
    "\n",
    "    # early stopping\n",
    "    es_checkpoint = EarlyStopping(\n",
    "        monitor=stopping_moniter,\n",
    "        patience=stopping_patience,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    \n",
    "    # fit\n",
    "    history = model.fit(\n",
    "        x=X,\n",
    "        y=Y,\n",
    "        verbose=2,\n",
    "        callbacks=[tensorboard_callback, cp_callback, es_checkpoint],\n",
    "        **kwargs\n",
    "    )\n",
    "    model.save(model_dir / 'model.keras')\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_csv(model_dir / \"logs/history.csv\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AL_simulation(unlabelled: tuple, intial_labelled: tuple, test: tuple,\n",
    "                    model, name, sampling_query, pool_size, evaluate_metrics,\n",
    "                    num_iterations=10, epochs=10):\n",
    "    \n",
    "    X_unlabelled, Y_unlabelled = unlabelled\n",
    "    X_labelled, Y_labelled = intial_labelled\n",
    "    X_test, Y_test = test\n",
    "    \n",
    "    histories = []\n",
    "    iteration_metrics = {}\n",
    "    dir = MODEL_DIR / name\n",
    "    Path(dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        print(f\" --- Iteration {i + 1} --- \")\n",
    "        \n",
    "        labelling_budget =  len(Y_labelled) / len(Y_unlabelled)\n",
    "        id = f\"{name}_i={i}_LB={int(labelling_budget)}\"\n",
    "        \n",
    "        history = train(\n",
    "            model, X_labelled, Y_labelled,\n",
    "            epochs=epochs,\n",
    "            batch_size=128,\n",
    "            model_dir=MODEL_DIR / dir / id, \n",
    "        )\n",
    "        histories.append(history)\n",
    "        \n",
    "        # get metrics from test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_true = Y_test\n",
    "        iteration_metrics[id] = evaluate_metrics(y_true, y_pred)\n",
    "        \n",
    "        # active learning qeary on unlabelled set\n",
    "        y_pred = model.predict(X_unlabelled)\n",
    "        indexes_pool = sampling_query(y_pred, unlabelled_X, pool_size)\n",
    "        X_new = [X_unlabelled[i] for i in indexes_pool]\n",
    "        Y_new = [Y_unlabelled[i] for i in indexes_pool]\n",
    "        \n",
    "        # add the newly 'annotated' samples to the labelled set        \n",
    "        X_labelled = np.vstack((X_labelled, X_new))\n",
    "        Y_labelled = np.vstack((Y_labelled, Y_new))\n",
    "        \n",
    "        # remove the new samples from the unlabelled set\n",
    "        X_unlabelled = np.delete(X_unlabelled, indexes_pool, axis=0)\n",
    "        Y_unlabelled = np.delete(Y_unlabelled, indexes_pool, axis=0)\n",
    "        \n",
    "        print(\"current iteration metrics: \", iteration_metrics)\n",
    "        pd.DataFrame(history.history).to_csv(dir / id / 'hist.csv')\n",
    "        np.save(dir / 'metrics.npy', iteration_metrics)\n",
    "     \n",
    "    return iteration_metrics, histories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Iteration 1 --- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 4s - loss: 0.0183 - recall_1: 0.0065 - precision_1: 0.0338 - auc_pr: 0.0213 - auc_roc: 0.8032 - metric/map: 0.0083 - 4s/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0125 - recall_1: 0.0545 - precision_1: 0.7500 - auc_pr: 0.1776 - auc_roc: 0.8863 - metric/map: 0.0093 - 2s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0117 - recall_1: 0.0908 - precision_1: 0.7527 - auc_pr: 0.2300 - auc_roc: 0.9078 - metric/map: 0.0093 - 2s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0113 - recall_1: 0.1310 - precision_1: 0.8080 - auc_pr: 0.2678 - auc_roc: 0.8978 - metric/map: 0.0095 - 2s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0108 - recall_1: 0.1492 - precision_1: 0.8394 - auc_pr: 0.2961 - auc_roc: 0.9240 - metric/map: 0.0097 - 2s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0104 - recall_1: 0.1660 - precision_1: 0.8205 - auc_pr: 0.3245 - auc_roc: 0.9175 - metric/map: 0.0097 - 2s/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0101 - recall_1: 0.1764 - precision_1: 0.8144 - auc_pr: 0.3445 - auc_roc: 0.9247 - metric/map: 0.0098 - 2s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0097 - recall_1: 0.1933 - precision_1: 0.8232 - auc_pr: 0.3698 - auc_roc: 0.9352 - metric/map: 0.0099 - 2s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0096 - recall_1: 0.1958 - precision_1: 0.8436 - auc_pr: 0.3773 - auc_roc: 0.9338 - metric/map: 0.0099 - 2s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 10: saving model to /home/ec2-user/acoustic-AL/models/least_confidence_sampling/least_confidence_sampling_i=0_LB=0/training/checkpoint.weights.h5\n",
      "553/553 - 2s - loss: 0.0092 - recall_1: 0.2270 - precision_1: 0.8454 - auc_pr: 0.4093 - auc_roc: 0.9433 - metric/map: 0.0101 - 2s/epoch - 3ms/step\n",
      "2763/2763 [==============================] - 3s 1ms/step\n",
      "  95/8842 [..............................] - ETA: 9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 09:10:57.789232: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1158885376 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8842/8842 [==============================] - 9s 1ms/step\n",
      "current iteration metrics:  {'least_confidence_sampling_i=0_LB=0': {0: (0.7, 0.044444446), 1: (0.7266187, 0.541555), 2: (0.0, 0.0), 3: (0.72727275, 0.046511628)}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m         classwize[i] \u001b[38;5;241m=\u001b[39m (precision, recall)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m classwize    \n\u001b[0;32m---> 27\u001b[0m iteration_metrics, histories \u001b[38;5;241m=\u001b[39m \u001b[43mAL_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43munlabelled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munlabelled_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlabelled_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintial_labelled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabelled_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelled_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleast_confidence_sampling\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision_recall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# iterations\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleast_confidence_sampling\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 49\u001b[0m, in \u001b[0;36mAL_simulation\u001b[0;34m(unlabelled, intial_labelled, test, model, name, sampling_query, pool_size, evaluate_metrics, num_iterations, epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent iteration metrics: \u001b[39m\u001b[38;5;124m\"\u001b[39m, iteration_metrics)\n\u001b[1;32m     48\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(history\u001b[38;5;241m.\u001b[39mhistory)\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration_metrics\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(\u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m iteration_metrics, histories\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "compile(model)\n",
    "\n",
    "def least_confidence_sampling(y_pred, unlabelled_X, pool_size):\n",
    "    # Calculate least confidence (1 - max probability)\n",
    "    least_confidence_scores = 1 - np.max(y_pred, axis=1)\n",
    "\n",
    "    # Select the least confident instances\n",
    "    uncertain_indices = np.argsort(least_confidence_scores)[:pool_size]\n",
    "    return uncertain_indices\n",
    "\n",
    "def precision_recall(y_true, y_pred):\n",
    "    classwize = {}\n",
    "    for i in range(4):\n",
    "        m = keras.metrics.Precision(thresholds=0.5)\n",
    "        m.update_state(y_true[:, i], y_pred[:, i])\n",
    "        precision = m.result().numpy()\n",
    "        \n",
    "        m = keras.metrics.Recall(thresholds=0.5)\n",
    "        m.update_state(y_true[:, i], y_pred[:, i])\n",
    "        recall = m.result().numpy()\n",
    "        \n",
    "        classwize[i] = (precision, recall)\n",
    "    \n",
    "    return classwize    \n",
    "\n",
    "iteration_metrics, histories = AL_simulation(\n",
    "    \n",
    "        unlabelled=(unlabelled_X, unlabelled_Y), \n",
    "        intial_labelled=(labelled_X, labelled_Y), \n",
    "        test=(test_X, test_Y),\n",
    "        model=model, \n",
    "        name='least_confidence_sampling', \n",
    "        evaluate_metrics=precision_recall,\n",
    "        pool_size= int(len(X) / 20), # iterations\n",
    "        num_iterations=20,\n",
    "        sampling_query=least_confidence_sampling\n",
    "        \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(test_X)\n\u001b[1;32m      3\u001b[0m m \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mPrecision(thresholds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      4\u001b[0m m\u001b[38;5;241m.\u001b[39mupdate_state(test_Y[:, \u001b[38;5;241m0\u001b[39m], y_pred[:, \u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = model(test_X)\n",
    "\n",
    "m = keras.metrics.Precision(thresholds=0.5)\n",
    "m.update_state(test_Y[:, 0], y_pred[:, 0])\n",
    "m.result()\n",
    "                                                                                                                                                                                                                                3: (0.71428573, 0.10471204)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, batched_test_dataset):\n",
    "    y_true, y_pred = [], []\n",
    "    for batch_X, batch_y in batched_test_dataset, desc='loading/predicting test ds':\n",
    "        predictions = model(batch_X, training=False)\n",
    "        y_true.extend(batch_y.numpy())\n",
    "        y_pred.extend(predictions.numpy()) \n",
    "\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    y_true_flat = y_true.reshape(-1, 4)\n",
    "    y_pred_flat = y_pred.reshape(-1, 4)\n",
    "    \n",
    "    m = keras.metrics.AUC(curve='roc')\n",
    "    m.update_state(y_true_flat[:, 0], y_pred_flat[:, 0])\n",
    "    m.result()\n",
    "    \n",
    "    m = keras.metrics.AUC(curve='pr')\n",
    "    m.update_state(y_true_flat[:, 0], y_pred_flat[:, 0])\n",
    "    m.result()\n",
    "    \n",
    "    for i in range(4):\n",
    "        print('\\n class ', i)\n",
    "        y_pred_binary = (y_pred_flat[:, i] >= threshold).astype(int)\n",
    "\n",
    "        precision_metric = Precision()\n",
    "        recall_metric = Recall()\n",
    "\n",
    "        precision_metric.update_state(y_true_flat[:, i], y_pred_binary)\n",
    "        recall_metric.update_state(y_true_flat[:, i], y_pred_binary)\n",
    "\n",
    "        precision = precision_metric.result().numpy()\n",
    "        recall = recall_metric.result().numpy()\n",
    "\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        \n",
    "        ...\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
