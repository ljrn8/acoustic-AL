{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:config:Debug logging active\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from config import *\n",
    "from preprocessing import SpectrogramSequence\n",
    "from util import Dataset\n",
    "\n",
    "ds = Dataset(DATA_ROOT)\n",
    "annotations_df: pd.DataFrame = pd.read_csv(ANNOTATIONS / 'initial_dataset_7depl_metadata.csv')\n",
    "has_annotations = \"1_20230316_063000.wav\"\n",
    "has_annotations_path = ds.get_data_path(1, 1) / has_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 256, 428, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 128, 428, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 64, 428, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 32, 428, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 16, 428, 128)      73856     \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 8, 428, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 4, 428, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 2, 428, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 219136)            0         \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 428, 512)          0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 428, 128)          328192    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 428, 4)            516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 716,548\n",
      "Trainable params: 716,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# NOTE paper has only 40 freq bins for chunk (i have >500 - too high sr?)\n",
    "\n",
    "def CRNN(input_shape, num_classes, n_filters):\n",
    "    freq_len, time_len, _ = input_shape\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    \n",
    "    # CNN layers\n",
    "    for filters in n_filters:\n",
    "        model.add(layers.Conv2D(filters, (3, 3), activation='relu', padding='same', strides=(2, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 1))) # frequency pooling only\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Reshape((time_len, -1))) # input matrix for RNN shape=(new_features, time_frames)\n",
    "\n",
    "    # RNN layers\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "    model.add(layers.Dense(num_classes, activation='sigmoid'))  \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = CRNN(input_shape=(512, 428, 1), num_classes=4, n_filters=[32, 64, 128, 256])\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "keras.utils.plot_model(model, to_file = FIGURES_DIR / 'model.png', \n",
    "                       show_shapes=True,  expand_nested=True, rankdir='TR')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle annotations but keep recordings clumped\n",
    "in order to maintain class balance between train/test/valid (deployments are inbalanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = annotations_df.groupby('recording')\n",
    "\n",
    "shuffled_groups = list(grouped)  \n",
    "np.random.shuffle(shuffled_groups)  \n",
    "\n",
    "shuffled_df = pd.concat([df for _, df in shuffled_groups], ignore_index=True)\n",
    "\n",
    "shuffled_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 13)\n",
      "(438, 13)\n",
      "(1401, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(shuffled_df, test_size=0.2, shuffle=False)\n",
    "train_df, validation_df = train_test_split(train_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "for i in (validation_df, test_df, train_df):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n# frames in chunk:  428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing data: 100%|██████████| 188/188 [00:01<00:00, 98.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n# frames in chunk:  428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing data: 100%|██████████| 69/69 [00:00<00:00, 95.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n# frames in chunk:  428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing data: 100%|██████████| 46/46 [00:00<00:00, 120.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11280\n",
      "4140\n",
      "2757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sr = 22_000\n",
    "batch = 32\n",
    "\n",
    "train_sequence = SpectrogramSequence(annotations_df=train_df, sr=sr, batch_size=batch)\n",
    "test_sequence = SpectrogramSequence(annotations_df=test_df, sr=sr, batch_size=batch)\n",
    "validation_sequence = SpectrogramSequence(annotations_df=validation_df, sr=sr, batch_size=batch)\n",
    "\n",
    "for s in (train_sequence, test_sequence, validation_sequence):\n",
    "    print(len(s.chunk_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading new recording: 1_20230317_063000.wav "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/working/acoustic-AL/acoustic-AL/preprocessing.py:107: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  samplerate, s = wavfile.read(recording_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Time Taken: 1.996114 seconds\n",
      "resampling 1_20230317_063000.wav  -> Time Taken: 2.076659 seconds\n",
      "stft 1_20230317_063000.wav  -> Time Taken: 0.741147 seconds\n",
      "converting to db 1_20230317_063000.wav "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/.local/lib/python3.8/site-packages/maad/util/miscellaneous.py:413: RuntimeWarning: divide by zero encountered in log10\n",
      "  y = 10*log10(x)   # take log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Time Taken: 1.491110 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:batch average spectrogram chunk shape: [512. 428.]\n",
      "DEBUG:root:batch average Y shape: [428.   4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 6.32 seconds\n",
      "(512, 428) (428, 4)\n"
     ]
    }
   ],
   "source": [
    "batch_X, batch_Y = train_sequence.__getitem__(0)\n",
    "print(batch_X[0].shape, batch_Y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3396), started 0:19:07 ago. (Use '!kill 3396' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-55ecf63b9c68a616\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-55ecf63b9c68a616\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading new recording: 1_20230317_063000.wav  -> Time Taken: 2.149228 seconds\n",
      "resampling 1_20230317_063000.wav  -> Time Taken: 2.710153 seconds\n",
      "stft 1_20230317_063000.wav  -> Time Taken: 0.779940 seconds\n",
      "converting to db 1_20230317_063000.wav  -> Time Taken: 1.637075 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:batch average spectrogram chunk shape: [512. 428.]\n",
      "DEBUG:root:batch average Y shape: [428.   4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7.29 seconds\n",
      "Epoch 1/30\n",
      "loading new recording: 1_20230520_170000.wav  -> Time Taken: 2.173433 seconds\n",
      "resampling 1_20230520_170000.wav  -> Time Taken: 2.172781 seconds\n",
      "stft 1_20230520_170000.wav  -> Time Taken: 0.836231 seconds\n",
      "converting to db 1_20230520_170000.wav  -> Time Taken: 1.515275 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:batch average spectrogram chunk shape: [512. 428.]\n",
      "DEBUG:root:batch average Y shape: [428.   4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 6.71 seconds\n",
      "loading new recording: 1_20230520_073000.wav "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 06:40:02.541162: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 448790528 exceeds 10% of free system memory.\n",
      "2024-08-17 06:40:03.418320: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 224395264 exceeds 10% of free system memory.\n",
      "2024-08-17 06:40:03.778693: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 224395264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Time Taken: 8.279658 seconds\n",
      "resampling 1_20230520_073000.wav  -> Time Taken: 8.708125 seconds\n",
      "stft 1_20230520_073000.wav  -> Time Taken: 1.725249 seconds\n",
      "converting to db 1_20230520_073000.wav  -> Time Taken: 1.943007 seconds\n",
      "Total: 20.67 seconds\n",
      "loading new recording: 1_20230520_170000.wav  -> Time Taken: 8.945539 seconds\n",
      "resampling 1_20230520_170000.wav "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 06:40:39.782159: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 224395264 exceeds 10% of free system memory.\n",
      "2024-08-17 06:40:39.791227: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 224395264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Time Taken: 14.844863 seconds\n",
      "stft 1_20230520_170000.wav  -> Time Taken: 8.368051 seconds\n",
      "converting to db 1_20230520_170000.wav  -> Time Taken: 2.758359 seconds\n",
      "Total: 35.43 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:batch average spectrogram chunk shape: [512. 428.]\n",
      "DEBUG:root:batch average Y shape: [428.   4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/352 [..............................] - ETA: 7:35:37 - loss: 0.7979 - accuracy: 0.4736loading new recording: 1_20230417_070000.wav  -> Time Taken: 8.837759 seconds\n",
      "resampling 1_20230417_070000.wav  -> Time Taken: 16.551825 seconds\n",
      "  2/352 [..............................] - ETA: 3:06:06 - loss: 0.5818 - accuracy: 0.2380 -> Time Taken: 4.687324 seconds\n",
      "converting to db 1_20230417_070000.wav  -> Time Taken: 1.854192 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:batch average spectrogram chunk shape: [512. 428.]\n",
      "DEBUG:root:batch average Y shape: [428.   4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 32.03 seconds\n",
      "loading new recording: 1_20230520_070000.wav  -> Time Taken: 5.158581 seconds\n",
      "resampling 1_20230520_070000.wav  -> Time Taken: 4.374818 seconds\n",
      "stft 1_20230520_070000.wav  -> Time Taken: 1.641840 seconds\n",
      "converting to db 1_20230520_070000.wav  -> Time Taken: 2.792213 seconds\n",
      "Total: 14.02 seconds\n",
      "loading new recording: 1_20230520_073000.wav  -> Time Taken: 3.681121 seconds\n",
      "resampling 1_20230520_073000.wav  -> Time Taken: 4.372903 seconds\n",
      "stft 1_20230520_073000.wav  -> Time Taken: 1.993736 seconds\n",
      "converting to db 1_20230520_073000.wav  -> Time Taken: 5.652489 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:batch average spectrogram chunk shape: [512. 428.]\n",
      "DEBUG:root:batch average Y shape: [428.   4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 15.75 seconds\n",
      "  3/352 [..............................] - ETA: 3:20:53 - loss: 0.4517 - accuracy: 0.4920loading new recording: 1_20230317_073000.wav  -> Time Taken: 3.999090 seconds\n",
      "resampling 1_20230317_073000.wav  -> Time Taken: 5.491243 seconds\n",
      "stft 1_20230317_073000.wav  -> Time Taken: 2.657402 seconds\n",
      "converting to db 1_20230317_073000.wav  -> Time Taken: 3.216522 seconds\n",
      "Total: 15.40 seconds\n",
      "loading new recording: 1_20230317_163000.wav  -> Time Taken: 3.962677 seconds\n",
      "resampling 1_20230317_163000.wav  -> Time Taken: 5.412547 seconds\n",
      "stft 1_20230317_163000.wav "
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "# early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_prc',\n",
    "#     verbose=1,\n",
    "#     patience=30,\n",
    "#     mode='max',\n",
    "#     restore_best_weights=True\n",
    "# )\n",
    "\n",
    "checkpoint_path = MODEL_DIR / 'training_1' / 'crnn.ckpt'\n",
    "Path(checkpoint_path).parent.mkdir(exist_ok=True)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "import datetime\n",
    "now_str =  datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + now_str\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_sequence, \n",
    "    epochs=epochs, \n",
    "    validation_data=validation_sequence, \n",
    "    callbacks=[tensorboard_callback, cp_callback])\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(log_dir + \"hist.csv\")\n",
    "df[['prc', 'val_prc', 'recall', 'val_recall']].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
