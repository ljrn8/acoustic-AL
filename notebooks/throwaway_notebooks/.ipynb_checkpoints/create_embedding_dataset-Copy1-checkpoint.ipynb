{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b75b34-8c47-4860-97de-b3c20330ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow  import keras\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "import librosa \n",
    "from util import WavDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d671c86-7010-4a17-830a-ea564914a5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = 16_000\n",
    "\n",
    "def compute_frame_labels(label_tensor, frame_length=int(sr*0.96), step_size=int(sr*0.48), threshold=0.15):\n",
    "    n_labels, total_samples = label_tensor.shape\n",
    "    n_frames = total_samples // step_size \n",
    "    \n",
    "    frame_labels = np.zeros((n_labels, n_frames), dtype=int)\n",
    "    \n",
    "    for i in range(n_frames):\n",
    "        start = i * step_size\n",
    "        end = start + frame_length\n",
    "        frame = label_tensor[:, start:end]\n",
    "        \n",
    "        # is there >15% annotations in the frame\n",
    "        frame_label = (np.mean(frame, axis=1) >= threshold).astype(int)\n",
    "        frame_labels[:, i] = frame_label\n",
    "    \n",
    "    return frame_labels\n",
    "\n",
    "Y = np.zeros((4, 16_000 * 5))\n",
    "Y[0, 32_000:] = 1\n",
    "Y[2, :32_000] = 1\n",
    "Y[3, -8_000:] = 1\n",
    "compute_frame_labels(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5ee9b9-a9d9-491d-815c-26ade202f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:44:36 INFO Using /tmp/tfhub_modules to cache modules.\n",
      "2024-09-08 21:44:37.244922: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "yamnet_url = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_layer = hub.KerasLayer(yamnet_url, input_shape=(None,), dtype=tf.float32, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8003760-f172-4094-9208-2b696016af0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' mean': 14.459999999999999,\n",
       " ' median': 3.3,\n",
       " ' min': 0.0,\n",
       " ' max': 62.0,\n",
       " ' sum': 72.3,\n",
       " ' std_dev': 23.826170485413723,\n",
       " ' var': 567.6863999999999}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_TOKENS = {        \n",
    "    \"fast_trill_6khz\": 0, \n",
    "    \"nr_syllable_3khz\": 1,\n",
    "    \"triangle_3khz\": 2,   \n",
    "    \"upsweep_500hz\": 3,   \n",
    "}\n",
    "def summarize(arr, name=\"\"):\n",
    "    return {\n",
    "        f'{name} mean': np.mean(arr),\n",
    "        f'{name} median': np.median(arr),\n",
    "        f'{name} min': np.min(arr),\n",
    "        f'{name} max': np.max(arr),\n",
    "        f'{name} sum': np.sum(arr),\n",
    "        f'{name} std_dev': np.std(arr),\n",
    "        f'{name} var': np.var(arr),\n",
    "    }\n",
    "\n",
    "summarize([0, 3.3, 2, 5, 62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cdf7f6d-4292-4d31-8a72-68ea971ab7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [3:28:53, 13.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "import h5py\n",
    "\n",
    "hdf5_file = INTERMEDIATE / 'samples_train.hdf5'\n",
    "new_ds = INTERMEDIATE / 'train.hdf5'\n",
    "old_ds = h5py.File(hdf5_file, 'r')\n",
    "\n",
    "\n",
    "def process_samples(chunk):\n",
    "    _, embedds, _ = yamnet_layer(chunk)\n",
    "    return embedds\n",
    "    \n",
    "\n",
    "with h5py.File(new_ds, 'w') as new_ds:\n",
    "    for i, rec in tqdm(enumerate(\n",
    "        list(old_ds)\n",
    "    )):\n",
    "        \n",
    "        Y = old_ds[rec]['Y']  \n",
    "        X = old_ds[rec]['X']\n",
    "        \n",
    "        chunk = 5 * sr # 5 second chunks\n",
    "        hop = 1 * sr # 1 second overlaps\n",
    "        \n",
    "        n_samples = Y.shape[1]\n",
    "\n",
    "        for start in range(0, n_samples - chunk, chunk - hop):\n",
    "\n",
    "            group = new_ds.create_group(f\"chunk_{i}_{start}\")  \n",
    "\n",
    "            embedds = process_samples(X[start:start+chunk])\n",
    "            group.create_dataset(\"X\", data=embedds, dtype=np.float32) \n",
    "            \n",
    "            label_frames = compute_frame_labels(Y[:, star    t:start+chunk])\n",
    "            group.create_dataset(\"Y\", data=label_frames, dtype=bool) \n",
    "\n",
    "            # chunk metadata\n",
    "            group.attrs['recording'] = rec\n",
    "            group.attrs['start_time'] = start // sr\n",
    "            group.attrs['end_time'] = (start + chunk) // sr\n",
    "            group.attrs['shapes'] = (embedds.shape, label_frames.shape)\n",
    "            group.attrs['classwize_labeled_frame_counts'] = [\n",
    "                sum(label_frames[index, :]) for label, index in DEFAULT_TOKENS.items()\n",
    "            ]\n",
    "\n",
    "            for key, val in summarize(embedds, \"embedding_summary\").items():\n",
    "                group.att   rs[key] = val\n",
    "\n",
    "            for key, val in summarize(label_frames, \"label_summary\").items():\n",
    "                group.attrs[key] = val\n",
    "\n",
    "\n",
    "\n",
    "old_ds.close() \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
