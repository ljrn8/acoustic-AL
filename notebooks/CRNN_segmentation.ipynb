{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from config import *\n",
    "from preprocessing import SpectrogramSequence\n",
    "from util import Dataset\n",
    "\n",
    "annotations_df: pd.DataFrame = pd.read_csv(ANNOTATIONS / 'initial_dataset_7depl_metadata.csv')\n",
    "has_annotations = \"1_20230316_063000.wav\"\n",
    "has_annotations_path = ds.get_data_path(1, 1) / has_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 21:18:06.327612: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 428, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 428, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 428, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 428, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 428, 128)      73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 428, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 428, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 428, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 219136)            0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 512, 428)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 512, 128)          285184    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512, 4)            516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,540\n",
      "Trainable params: 673,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# NOTE paper has only 40 freq bins for chunk (i have >500 - too high sr?)\n",
    "\n",
    "def CRNN(input_shape, num_classes, n_filters):\n",
    "    freq_len, time_len, _ = input_shape\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    \n",
    "    # CNN layers\n",
    "    for filters in n_filters:\n",
    "        model.add(layers.Conv2D(filters, (3, 3), activation='relu', padding='same', strides=(2, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 1))) # frequency pooling only\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Reshape((-1, time_len))) # input matrix for RNN shape=(new_features, time_frames)\n",
    "\n",
    "    # RNN layers\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "    model.add(layers.Dense(num_classes, activation='sigmoid'))  \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = CRNN(input_shape=(512, 428, 1), num_classes=4, n_filters=[32, 64, 128, 256])\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle annotations but keep recordings clumped\n",
    "in order to maintain class balance between train/test/valid (deployments are inbalanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = annotations_df.groupby('recording')\n",
    "\n",
    "shuffled_groups = list(grouped)  \n",
    "np.random.shuffle(shuffled_groups)  \n",
    "\n",
    "shuffled_df = pd.concat([df for _, df in shuffled_groups], ignore_index=True)\n",
    "\n",
    "shuffled_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 13)\n",
      "(438, 13)\n",
      "(1401, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(shuffled_df, test_size=0.2, shuffle=False)\n",
    "train_df, validation_df = train_test_split(train_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "for i in (validation_df, test_df, train_df):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n# frames in chunk:  428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing data: 100%|██████████| 188/188 [00:09<00:00, 20.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n# frames in chunk:  428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing data: 100%|██████████| 78/78 [00:03<00:00, 20.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n# frames in chunk:  428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing data: 100%|██████████| 37/37 [00:01<00:00, 33.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11280\n",
      "4677\n",
      "2220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sr = 22_000\n",
    "batch = 32\n",
    "\n",
    "train_sequence = SpectrogramSequence(annotations_df=train_df, sr=sr, batch_size=batch)\n",
    "test_sequence = SpectrogramSequence(annotations_df=test_df, sr=sr, batch_size=batch)\n",
    "validation_sequence = SpectrogramSequence(annotations_df=validation_df, sr=sr, batch_size=batch)\n",
    "\n",
    "for s in (train_sequence, test_sequence, validation_sequence):\n",
    "    print(len(s.chunk_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading new recording: 1_20230316_063000.wav \t\t\t| Time Taken: 5.862738 seconds\n",
      "resampling 1_20230316_063000.wav \t\t\t| Time Taken: 2.092499 seconds\n",
      "stft 1_20230316_063000.wav \t\t\t| Time Taken: 1.383413 seconds\n",
      "converting to db 1_20230316_063000.wav \t\t\t| Time Taken: 0.949440 seconds\n",
      "Total: 10.30 seconds\n",
      "(512, 428) (428, 4)\n"
     ]
    }
   ],
   "source": [
    "batch_X, batch_Y = train_sequence.__getitem__(0)\n",
    "print(batch_X[0].shape, batch_Y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading new recording: 1_20230317_063000.wav \t\t\t| Time Taken: 17.887911 seconds\n",
      "resampling 1_20230317_063000.wav \t\t\t| Time Taken: 12.127509 seconds\n",
      "stft 1_20230317_063000.wav \t\t\t| Time Taken: 3.312986 seconds\n",
      "converting to db 1_20230317_063000.wav \t\t\t| Time Taken: 1.146981 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:batch average spectrogram chunk shape: [512. 428.]\n",
      "DEBUG:root:batch average Y shape: [428.   4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 34.49 seconds\n",
      "Epoch 1/2\n",
      "loading new recording: 1_20230514_060000.wav \t\t\t| Time Taken: 11.318040 seconds\n",
      "resampling 1_20230514_060000.wav \t\t\t| Time Taken: 3.394469 seconds\n",
      "stft 1_20230514_060000.wav \t\t\t| Time Taken: 2.291393 seconds\n",
      "converting to db 1_20230514_060000.wav \t\t\t| Time Taken: 1.719308 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:batch average spectrogram chunk shape: [512. 428.]\n",
      "DEBUG:root:batch average Y shape: [428.   4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 18.74 seconds\n",
      "loading new recording: 1_20230317_063000.wav "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 21:21:56.221283: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 448790528 exceeds 10% of free system memory.\n",
      "2024-08-16 21:21:59.082725: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 224395264 exceeds 10% of free system memory.\n",
      "2024-08-16 21:22:16.719062: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 224395264 exceeds 10% of free system memory.\n",
      "2024-08-16 21:22:24.978124: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 112197632 exceeds 10% of free system memory.\n",
      "2024-08-16 21:22:26.061184: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 112197632 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "# early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_prc',\n",
    "#     verbose=1,\n",
    "#     patience=30,\n",
    "#     mode='max',\n",
    "#     restore_best_weights=True\n",
    "# )\n",
    "\n",
    "history = model.fit(\n",
    "    train_sequence, \n",
    "    epochs=epochs, \n",
    "    validation_data=validation_sequence)\n",
    "                    # callbacks=[early_stopping_cb])\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df[['prc', 'val_prc', 'recall', 'val_recall']].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
