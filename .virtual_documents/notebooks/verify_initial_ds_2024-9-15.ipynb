get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")

from config import *
from dataset import WavDataset

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import librosa 
import os
import h5py
import pickle

from pathlib import Path
from config import *
from maad import sound, util
from maad.rois import template_matching


os.listdir(ANNOTATIONS / 'manual_annotations')


annotations = pd.read_csv(ANNOTATIONS / 'manual_annotations' / 'initial_manual_annotations.csv')
annotations





# with open(ANNOTATIONS / 'manual_annotations' / 'initial_training_recordings.pkl', 'rb') as f:
#     training_recs = np.array(pickle.load(f))

# annotations_df = pd.read_csv(ANNOTATIONS / 'manual_annotations' / 'initial_manual_annotations.csv')
# annotated = np.array(annotations_df['recording'].unique())
# len(training_recs), len(annotated)


unnannotated = training_recs[~np.isin(training_recs, annotated)]
len(unnannotated)


templates = pd.read_csv(CORRELATIONS / 'templates.csv')
labels = ['nr_syllable_3khz', 'fast_trill_6khz', 'upsweep_500hz', 'triangle_3khz']
templates = templates[templates['name'].isin(labels)]
numerical = ['low', 'high', 'start', 'end']
templates[numerical] = templates[numerical].astype(float)

nperseg = 1024
noverlap = 512
window = 'hann'
db_range = 80

def process_spec(path, flims, tlims):
    s, fs = sound.load(path)
    Sxx_template, _, _, _ = sound.spectrogram(s, fs, window, nperseg, noverlap, flims, tlims)
    return util.power2dB(Sxx_template, db_range)

ds = WavDataset()
spectrograms = { # should have just done a list
    row['name']: (
        process_spec(
            ds[row['recording']], (row['low'], row['high']), (row['start'], row['end'])
        ), row
    )
    
    for i, row in templates.iterrows()
}

{label: (S.shape) for label, (S, row) in spectrograms.items()}


from tqdm import tqdm

def template_xcoefs(rec, significance_thresh=0.30):
    s, fs = sound.load(ds[rec])
    xcoefs = {}
    for template_name, (Sxx_template, info) in spectrograms.items():
        Sxx_audio, tn, fn, ext = sound.spectrogram(
            s, fs, window, nperseg, noverlap, 
            flims=(info['low'], info['high'])
        )
        Sxx_audio = util.power2dB(Sxx_audio, db_range)
        xcorrcoef, rois = template_matching(Sxx_audio, Sxx_template, tn, ext, significance_thresh)
        xcoefs[template_name] = rois['xcorrcoef']
    
    return xcoefs

correlations = {}
for rec in tqdm(unnannotated, desc='correlating'):
    correlations[rec] = template_xcoefs(rec)
    with open('objects/non_annotated_coefs.pkl', 'wb') as f:
        pickle.dump(correlations, f)


with open("objects/non_annotated_coefs.pkl", 'rb') as f:
    correlations = pickle.load(f)

def print_counts(xcoefs, thresh):
    for label, x in xcoefs.items():
        x = np.array(x)
        filtered = x[x > thresh]
        print(f'{label}: {len(filtered)}, mean={filtered.mean():.3f}', end = "\t")
    
for rec, xcoefs in list(correlations.items())[:50]:
    print('\n\n' + rec)
    for thresh in [0.001, 0.3, 0.4, 0.5, 0.6, 0.7]:
        print("")
        print_counts(xcoefs, thresh)        


correlation_all =  [
    (rec, np.concatenate([x for label, x in xcoefs.items()]))
    for rec, xcoefs in list(correlations.items())
]
correlation_all[0][1].mean(), len(correlation_all)


Proposed_cutoff = 0.45
filt = [rec for rec, x in correlation_all if (x < Proposed_cutoff).all()]
len(filt)


signalless_recordings = filt
initial_dataset_recordings = np.concatenate((filt, annotated))
len(initial_dataset_recordings)


np.save(ANNOTATIONS / 'manual_annotations' / 'all_annotated_recordings_filtered.npy', initial_dataset_recordings)
np.save(ANNOTATIONS / 'manual_annotations' / 'signalless_recordings.npy', signalless_recordings)
