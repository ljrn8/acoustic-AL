get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")

import numpy as np

import librosa 
import matplotlib.pyplot as plt
from tqdm import tqdm
from config import *
import h5py
from util import DEFAULT_TOKENS
import librosa


X = np.load(INTERMEDIATE / 'logmel_multiclass_noise.npy')
Y = np.load(INTERMEDIATE / 'logmel_labels_multiclass_noise.npy')


len(X) // 10


from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances

def _partial_av_similiarities(flat_X, partitions=30):
    step = len(X) // partitions
    avs = []
    for i in tqdm(range(0, len(X) - step, step)):
        p = pairwise_distances(flat_X[i:i+step, :], flat_X[i:i+step, :])
        avg_similarities = np.mean(p, axis=1)
        avs.extend(avg_similarities)
    return avs            

X_fl = np.array([x.flatten() for x in X]) 
_partial_av_similiarities(X_fl)


x = X[0].flatten().reshape(1, -1)


import keras_cv
from AL import build_resnet16, AL_split
from keras.callbacks import EarlyStopping


model = build_resnet16((40, 107, 1))
model.compile(optimizer='adam',
        loss=keras_cv.losses.FocalLoss(alpha=0.25, gamma=2))

init, pool, test = AL_split(X, Y)

initial_X, initial_Y = init
pool_X, pool_Y = pool
test_X, test_Y = test

earlystopping_cp = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True,
)
model.fit(
    # x=pool_X[query_indices], y=pool_Y[query_indices], for query-wise training
    x=initial_X, y=initial_Y, # full model reset
    epochs=10, verbose=2, 
    validation_data=(test_X, test_Y),
    batch_size=32,
    callbacks=[earlystopping_cp]
)    



def get_embeddings(model, X):
    from tensorflow.keras.models import Model
    embeddings_layer = model.layers[-2].output  
    output_layer = model.output  
    combined_model = Model(inputs=model.input, outputs=[embeddings_layer, output_layer])
    embeddings, labels = combined_model.predict(X, verbose=2)
    return embeddings, labels



embs, preds = get_embeddings(model, X)
embs.shape


preds[:, :4].shape




labelled_embs = np.array([
    e for (e, p) in zip(embs, preds) if (p[:4] > 0.5).any() 
])

labelled_p = np.array([
    p for (e, p) in zip(embs, preds) if (p[:4] > 0.5).any() 
])


from sklearn.cluster import DBSCAN

# Step 1: Initialize DBSCAN
dbscan = DBSCAN(eps=20, min_samples=5)

# Step 2: Fit the model
dbscan.fit(embs)

# Step 3: Get cluster labels
dbscan_labels = dbscan.labels_


from sklearn.decomposition import PCA

pca = PCA(n_components=2)
reduced_data = pca.fit_transform(embs)


[np.where(p)[0][0] for p in labelled_p[:3] > 0.5]


# Optional: Visualize the results

ccs = ['red', 'green', 'blue', 'yellow']
c = [ccs[np.where(p)[0][0]] for p in preds > 0.5]

plt.figure(figsize=(10, 8))

plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=c, cmap='viridis', s=1)
plt.title('DBSCAN Clustering Results (PCA-reduced)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.colorbar(label='Cluster Label')
plt.show()


X[0]



log_mel_spectrogram = X[0]

# Step 3: Compute MFCCs from the log-Mel spectrogram
mfccs = librosa.feature.mfcc(S=log_mel_spectrogram, n_mfcc=13)

# Optional: Visualize the log-Mel spectrogram and MFCCs
plt.figure(figsize=(12, 8))

# Log-Mel Spectrogram
plt.subplot(2, 1, 1)
librosa.display.specshow(log_mel_spectrogram, x_axis='time', y_axis='mel', fmax=8000)
plt.title('Log-Mel Spectrogram')
plt.colorbar(format='%+2.0f dB')

# MFCCs
plt.subplot(2, 1, 2)
librosa.display.specshow(mfccs, x_axis='time')
plt.title('MFCCs')
plt.colorbar()

plt.tight_layout()
plt.show()


mfccs.shape






del mfccs
features = np.array([
    librosa.feature.mfcc(S=logmel, n_mfcc=20).flatten()
    for logmel in X
])



from sklearn_extra.cluster import KMedoids

kmedoids = KMedoids(n_clusters=5, random_state=0)
kmedoids.fit(features)

# Get the cluster labels
labels = kmedoids.labels_











import pickle
from util import LABELS

def plot_files(names):
    for name in names:
        with open(OUTPUT_DIR / 'AL' / name / 'metrics_overwrite.pkl', 'rb') as f:
            c = pickle.load(f)
            plot_map_inc(c)
    plt.legend(names)

def plot_map_inc(LB_metrics):
    x = [lb for lb, _ in LB_metrics]
    AP = np.zeros(shape=(4, len(x)))
    for i, l in enumerate(LABELS):
        # plt.plot(x, apc)
        AP[i] = np.array([m[l]['auc_pr'] for _, (m, mAP) in LB_metrics])

    plt.plot(x, AP.mean(axis=0))
    plt.ylim(0, 1)


plt.figure(figsize=(7, 5))
plot_files([
    'RS_colderstart_fulltrain_noresampling_6Q_0.25',
    'Entropy_colderstart_fulltrain_noresampling_20Q_0.3',
    'IDiv_pairwise_colderstart_fulltrain_noresampling_10Q_0.25'
])
plt.show() 



from util import *
from AL import *

with open('IDiv_pairwise_colderstart_fulltrain_noresampling_10Q_0.25' ,rb) as f:
    f.

LB_metrics = m
identity = 'entropy'
# AP curves
x = [lb for lb, _ in LB_metrics]
for i, l in enumerate(MULTICLASS_LABELS):
    # y = [m[l]['recall'] for _, (m, mAP) in LB_metrics] 
    # title = f'AP of {l} for {identity}'
    # plt.plot(x, y)

    # y = [m[l]['precision'] for _, (m, mAP) in LB_metrics] 
    # title = f'AP of {l} for {identity}'
    # plt.plot(x, y)

    y = [m[l]['auc_pr'] for _, (m, mAP) in LB_metrics] 
    title = f'AP of {l} for {identity}'
    plt.plot(x, y)

    
plt.ylim(0, 1)
plt.title('Entropy sampling (class-wise Average Precision)')
plt.show()





# mAP curve
AP = np.zeros(shape=(4, len(x)))
for i, l in enumerate(LABELS):
    AP[i] = np.array([m[l]['auc_pr'] for _, (m, mAP) in LB_metrics])

title = f'mAP for {identity}'
plt.figure(figsize=(20, 5))
plt.plot(x, AP.mean(axis=0))
plt.ylim(0, 1)
plt.title(title)
plt.show()


with open('../../output/AL/archive/RS (oversampled)/RS_metrics_oversampled.pkl', 'rb') as f:
    m2 = pickle.load(f)


LABELS


AP = np.zeros(shape=(4, len(x)))
AP_RS = np.zeros(shape=(4, len(m2)))

xx = [lb for lb, m in m2]

for i, l in enumerate(LABELS):
    AP[i] = np.array([m[l]['auc_pr'] for _, (m, mAP) in LB_metrics])
    AP_RS[i] = np.array([m[l]['auc_pr'] for _, m in m2])


title = f'mAP for RS (low resolution) vs Entropy'
plt.figure(figsize=(10, 2))

plt.plot(x, AP.mean(axis=0))

cap = int(0.25 * len(xx))
plt.plot(xx[ :cap], AP_RS.mean(axis=0)[:cap])

plt.ylim(0, 1)
plt.title(title)
plt.show()
